{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a825efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8471e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nvidia-ml-py3 \n",
    "%pip install openai \n",
    "%pip install datasets \n",
    "%pip install ipywidgets  \n",
    "%pip install widgetsnbextension \n",
    "%pip install pandas-profiling \n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4d096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import finnhub\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace9fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#START_DATE = input(\"Start Date: (yyyy-mm-dd)\")\n",
    "START_DATE = \"2022-12-31\"\n",
    "#END_DATE = \"2023-05-31\"\n",
    "#END_DATE = input(\"End Date: (yyyy-mm-dd)\")\n",
    "END_DATE = \"2024-01-18\"\n",
    "\n",
    "DATA_DIR = f\"./{START_DATE}_{END_DATE}\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0568da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "Cmlaql9r01qmnetgnp7gcmlaql9r01qmnetgnp80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_= load_dotenv(find_dotenv()) #read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai_api_key = openai.api_key\n",
    "print(openai_api_key)\n",
    "finnhub_api_key = os.environ['FINNHUB_IO_API_KEY']\n",
    "print(finnhub_api_key)\n",
    "finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
    "client = OpenAI(api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce2503",
   "metadata": {},
   "source": [
    "# Raw Financial Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6564114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_mapping(ret):\n",
    "    \n",
    "    up_down = 'U' if ret >= 0 else 'D'\n",
    "    integer = math.ceil(abs(100 * ret))\n",
    "    \n",
    "    return up_down + (str(integer) if integer <= 5 else '5+')\n",
    "\n",
    "\n",
    "def get_returns(stock_symbol):\n",
    "    \n",
    "    # Download historical stock data\n",
    "    print(stock_symbol, ': ', START_DATE, ' - ', END_DATE)\n",
    "    stock_data = yf.download(stock_symbol, start=START_DATE, end=END_DATE)\n",
    "    \n",
    "    weekly_data = stock_data['Adj Close'].resample('W').ffill()\n",
    "    weekly_returns = weekly_data.pct_change()[1:]\n",
    "    weekly_start_prices = weekly_data[:-1]\n",
    "    weekly_end_prices = weekly_data[1:]\n",
    "\n",
    "    weekly_data = pd.DataFrame({\n",
    "        'Start Date': weekly_start_prices.index,\n",
    "        'Start Price': weekly_start_prices.values,\n",
    "        'End Date': weekly_end_prices.index,\n",
    "        'End Price': weekly_end_prices.values,\n",
    "        'Weekly Returns': weekly_returns.values\n",
    "    })\n",
    "    \n",
    "    weekly_data['Bin Label'] = weekly_data['Weekly Returns'].map(bin_mapping)\n",
    "\n",
    "    return weekly_data\n",
    "\n",
    "def get_news(symbol, data):\n",
    "    \n",
    "    news_list = []\n",
    "    \n",
    "    for end_date, row in data.iterrows():\n",
    "        start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "        end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "        print(symbol, ': ', start_date, ' - ', end_date)\n",
    "        time.sleep(1) # control qpm\n",
    "        weekly_news = finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
    "        if len(weekly_news) > 0:\n",
    "            formatted_date = None  # Initialize 'formatted_date' outside the try block\n",
    "            try:\n",
    "                weekly_news_result = [{\n",
    "                    \"date\": datetime.fromtimestamp(n['datetime']).strftime('%Y-%m-%d'),\n",
    "                    \"headline\": n['headline'],\n",
    "                    \"summary\": n['summary'],\n",
    "                    } for n in weekly_news\n",
    "                ]\n",
    "            except:\n",
    "                print(\"Error with news line:\")\n",
    "                #if (lambda x: x.strftime('%Y%m%d%H%M%S') if isinstance(x, datetime) else None)(formatted_date)\n",
    "                #if (lambda x: x.strftime('%Y-%m-%d') if isinstance(x, datetime) else None)(formatted_date)\n",
    "                \n",
    "        else: \n",
    "            weekly_news_result = []\n",
    "        weekly_news_result.sort(key=lambda x: x.get('date', ''))\n",
    "        news_list.append(json.dumps(weekly_news_result))\n",
    "    \n",
    "    data['News'] = news_list\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_basics(symbol, data, always=False):\n",
    "    \n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    \n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    " \n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "        \n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "            \n",
    "    for i, row in data.iterrows():\n",
    "        \n",
    "        start_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "        last_start_date = START_DATE if i < 2 else data.loc[i-2, 'Start Date'].strftime('%Y-%m-%d')\n",
    "        \n",
    "        used_basic = {}\n",
    "        for basic in basic_list[::-1]:\n",
    "            if (always and basic['period'] < start_date) or (last_start_date <= basic['period'] < start_date):\n",
    "                used_basic = basic\n",
    "                break\n",
    "        final_basics.append(json.dumps(used_basic))\n",
    "        \n",
    "    data['Basics'] = final_basics\n",
    "    #print(\"done.....basics........\")\n",
    "    return data\n",
    "    \n",
    "\n",
    "def prepare_data_for_company(symbol, indice, with_basics=True):\n",
    "    \n",
    "    print(\"Getting returns...\")\n",
    "    data = get_returns(symbol)\n",
    "    print(\"Getting news...\")\n",
    "    #data = get_news(symbol, data)\n",
    "\n",
    "    if with_basics:\n",
    "        print(\"Getting basics...\")\n",
    "        data = get_basics(symbol, data)\n",
    "    #    data.to_csv(f\"{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}.csv\")\n",
    "    else:\n",
    "        data['Basics'] = [json.dumps({})] * len(data)\n",
    "    #    data.to_csv(f\"{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_nobasics.csv\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf02ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOW_30 = [\n",
    "    \"AXP\", \"AMGN\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\", \"HON\",\n",
    "    \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\", \"MSFT\", \"NKE\",\n",
    "    \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \"WMT\", \"DIS\", \"DOW\"\n",
    "    #,\"AAPL\"\n",
    "    ]\n",
    "\n",
    "NASDAQ_100 = [\n",
    "    \"MSFT\",\"AAPL\",\"AMZN\",\"NVDA\",\"AVGO\",\"META\",\"TSLA\",\"GOOGL\",\"GOOG\",\"COST\",\n",
    "    \"ADBE\",\"AMD\",\"PEP\",\"NFLX\",\"CSCO\",\"INTC\",\"TMUS\",\"CMCSA\",\"INTU\",\"AMGN\",\n",
    "    \"QCOM\",\"TXN\",\"HON\",\"AMAT\",\"ISRG\",\"BKNG\",\"VRTX\",\"GILD\",\"SBUX\",\"PANW\",\n",
    "    \"MDLZ\",\"REGN\",\"LRCX\",\"ADP\",\"PDD\",\"ADI\",\"MU\",\"MELI\",\"SNPS\",\"KLAC\",\"CDNS\",\n",
    "    \"CSX\",\"MAR\",\"PYPL\",\"CRWD\",\"ASML\",\"CTAS\",\"MNST\",\"WDAY\",\"ORLY\",\"ABNB\",\"ROP\",\n",
    "    \"LULU\",\"MRVL\",\"CHTR\",\"NXPI\",\"ADSK\",\"PCAR\",\"DXCM\",\"FTNT\",\"KHC\",\"ROST\",\"CPRT\",\n",
    "    \"MCHP\",\"KDP\",\"PAYX\",\"IDXX\",\"AEP\",\"ODFL\",\"AZN\",\"MRNA\",\"DASH\",\"DDOG\",\"CTSH\",\"EA\",\n",
    "    \"TEAM\",\"FAST\",\"CEG\",\"BIIB\",\"EXC\",\"VRSK\",\"ZS\",\"CSGP\",\"XEL\",\"GEHC\",\"ON\",\"BKR\",\"CCEP\",\n",
    "    \"GFS\",\"DLTR\",\"CDW\",\"TTD\",\"ANSS\",\"MDB\",\"TTWO\",\"FANG\",\"SPLK\",\"WBD\",\"ILMN\",\"SIRI\",\"WBA\",\n",
    "    ]\n",
    "\n",
    "# prepare_data_for_company(\"DOW\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d65960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting returns...\n",
      "MSFT :  2022-12-31  -  2024-01-18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m NASDAQ_100:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mprepare_data_for_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNASDAQ_100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m DOW_30:\n\u001b[0;32m      6\u001b[0m     prepare_data_for_company(symbol, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOW_30\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 101\u001b[0m, in \u001b[0;36mprepare_data_for_company\u001b[1;34m(symbol, indice, with_basics)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_for_company\u001b[39m(symbol, indice, with_basics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting returns...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mget_returns\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting news...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m#data = get_news(symbol, data)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mget_returns\u001b[1;34m(stock_symbol)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_returns\u001b[39m(stock_symbol):\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Download historical stock data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(stock_symbol, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, START_DATE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m, END_DATE)\n\u001b[1;32m---> 13\u001b[0m     stock_data \u001b[38;5;241m=\u001b[39m \u001b[43myf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_symbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEND_DATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     weekly_data \u001b[38;5;241m=\u001b[39m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdj Close\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mffill()\n\u001b[0;32m     16\u001b[0m     weekly_returns \u001b[38;5;241m=\u001b[39m weekly_data\u001b[38;5;241m.\u001b[39mpct_change()[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mf:\\0.MilindPython\\FinGPT\\FinGPT\\fingpt\\FinGPT_Forecaster\\.venv\\lib\\site-packages\\yfinance\\utils.py:103\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 103\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mf:\\0.MilindPython\\FinGPT\\FinGPT\\fingpt\\FinGPT_Forecaster\\.venv\\lib\\site-packages\\yfinance\\multi.py:163\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[0;32m    156\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[0;32m    157\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[0;32m    158\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[0;32m    159\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[0;32m    160\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    161\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[1;32m--> 163\u001b[0m         \u001b[43m_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\0.MilindPython\\FinGPT\\FinGPT\\fingpt\\FinGPT_Forecaster\\.venv\\lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for symbol in NASDAQ_100:\n",
    "    prepare_data_for_company(symbol, 'NASDAQ_100')\n",
    "\n",
    "for symbol in DOW_30:\n",
    "    prepare_data_for_company(symbol, 'DOW_30')\n",
    "#prepare_data_for_company(\"AAPL\", 'DOW_30')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af655d8b",
   "metadata": {},
   "source": [
    "# Generate Prompt from Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a53c0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def get_company_prompt(symbol):\n",
    "    \n",
    "    profile = finnhub_client.company_profile2(symbol=symbol)\n",
    "\n",
    "    company_name = profile['name']\n",
    "    company_template = \"[Company Introduction]:\\n\\n{name} is a leading entity in the {finnhubIndustry} sector. Incorporated and publicly traded since {ipo}, the company has established its reputation as one of the key players in the market. As of today, {name} has a market capitalization of {marketCapitalization:.2f} in {currency}, with {shareOutstanding:.2f} shares outstanding.\" \\\n",
    "        \"\\n\\n{name} operates primarily in the {country}, trading under the ticker {ticker} on the {exchange}. As a dominant force in the {finnhubIndustry} space, the company continues to innovate and drive progress within the industry.\"\n",
    "\n",
    "    formatted_str = company_template.format(**profile)\n",
    "    \n",
    "    return company_name,formatted_str\n",
    "\n",
    "def get_insider_sentiment(symbol):\n",
    "    \n",
    "    # Download insider sentiment \n",
    "    # Get insider sentiment data for US companies calculated using method discussed here. \n",
    "    # The MSPR ranges from -100 for the most negative to 100 for the most positive which can signal price changes in the \n",
    "    # coming 30-90 days.\n",
    "  \n",
    "    #for end_date, row in data.iterrows():\n",
    "    #    start_date = row['Start Date'].strftime('%Y-%m-%d')\n",
    "    #    end_date = row['End Date'].strftime('%Y-%m-%d')\n",
    "    #    print(symbol, ': ', start_date, ' - ', end_date)\n",
    "\n",
    "    time.sleep(1) # control qpm\n",
    "    insider_sentiment = finnhub_client.stock_insider_sentiment(symbol, _from=START_DATE, to=END_DATE)\n",
    "    #print(f\"Insider sentiment: \\n {insider_sentiment} from {START_DATE} to {END_DATE}\")\n",
    "\n",
    "    if len(insider_sentiment) > 0:\n",
    "         insider_sentiment_template = f\"[Insider Sentiment For]:{symbol} \\n\\n The insider sentiment information is shown below. \" \\\n",
    "        \"The MSPR ranges from -100 for the most negative to 100 for the most positive which can signal price changes in the coming 30-90 days.\"\n",
    "         if 'data' in insider_sentiment:\n",
    "             for n in insider_sentiment['data']:\n",
    "                #print(f\"insider informaiton - current: {n}\")\n",
    "                insider_sentiment_template +=  f\"\\nYear: {n['year']}      Month:  {n['month']}      Change:  {n['change']}       MSPR:  {n['mspr']}\"\n",
    "         else:\n",
    "             insider_sentiment_template += f\"\\n No insider information available\"\n",
    " \n",
    "    formatted_str = insider_sentiment_template.format(**insider_sentiment)\n",
    "    #print(formatted_str)\n",
    "    return formatted_str\n",
    "\n",
    "\n",
    "def get_prompt_by_row(symbol, company_name, row):\n",
    "\n",
    "    start_date = row['Start Date'] if isinstance(row['Start Date'], str) else row['Start Date'].strftime('%Y-%m-%d')\n",
    "    end_date = row['End Date'] if isinstance(row['End Date'], str) else row['End Date'].strftime('%Y-%m-%d')\n",
    "    term = 'increased' if row['End Price'] > row['Start Price'] else 'decreased'\n",
    "    head = \"From {} to {}, {}'s stock price {} from {:.2f} to {:.2f}. Company news during this period are listed below:\\n\\n\".format(\n",
    "        start_date, end_date, symbol, term, row['Start Price'], row['End Price'])\n",
    "    \n",
    "    news = []    \n",
    "    news_list = json.loads(row[\"News\"])\n",
    "    \n",
    "    for n in news_list:\n",
    "        if isinstance(n, dict) and 'date' in n:\n",
    "            #print(f'News structure: \\n {n}')\n",
    "            #print(f\"n['date'] : {n['date']}\")\n",
    "            if 'date' in n and n['date'][:8] <= end_date.replace('-', '') and not n['summary'].startswith(\"Looking for stock market analysis and research which proves results?\"):\n",
    "                if company_name in n['headline']: #If compnay name appears i the news headline\n",
    "                    formatted_news = \"[Headline]: {}\\n[Summary]: {}\\n\".format(n['headline'], n['summary'])\n",
    "                    news.append(formatted_news)\n",
    "\n",
    "    basics = json.loads(row['Basics'])\n",
    "\n",
    "    if basics:\n",
    "        # FIND ME\n",
    "        basics = \"\\n\\n Some recent basic financials of {}, reported on {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "        #print (f\"NOW......BASICS \\n {basics}\")\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "    \n",
    "    return head, news, basics\n",
    "\n",
    "\n",
    "def sample_news(news, k=5):\n",
    "    \n",
    "    return [news[i] for i in sorted(random.sample(range(len(news)), k))] # Random sample of news again FIND ME\n",
    "\n",
    "\n",
    "def map_bin_label(bin_lb):\n",
    "    \n",
    "    lb = bin_lb.replace('U', 'up by ')\n",
    "    lb = lb.replace('D', 'down by ')\n",
    "    lb = lb.replace('1', '0-1%')\n",
    "    lb = lb.replace('2', '1-2%')\n",
    "    lb = lb.replace('3', '2-3%')\n",
    "    lb = lb.replace('4', '3-4%')\n",
    "    if lb.endswith('+'):\n",
    "        lb = lb.replace('5+', 'more than 5%')\n",
    "#         lb = lb.replace('5+', '5+%')\n",
    "    else:\n",
    "        lb = lb.replace('5', '4-5%')\n",
    "    \n",
    "    return lb\n",
    "\n",
    "def calculate_30_day_ma(closing_prices):\n",
    "    ma_30 = []\n",
    "    for i in range(29, len(closing_prices)):\n",
    "        ma = sum(closing_prices[i - 29:i + 1]) / 30\n",
    "        ma_30.append(ma)\n",
    "    return ma_30\n",
    "\n",
    "#def get_all_prompts(symbol, min_past_weeks=1, max_past_weeks=3, with_basics=True): # FIND ME - MINIMUM PAST WEEKS = 1, AND MAXIMUM PAST WEEKS = 3...WHY?\n",
    "def get_all_prompts(symbol, min_past_weeks=1, max_past_weeks=5, with_basics=True): # changed to 5\n",
    "    \n",
    "    if with_basics:\n",
    "        try:\n",
    "            indice=\"DOW_30\"\n",
    "            df = pd.read_csv(f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}.csv')\n",
    "        except:\n",
    "            indice=\"NASDAQ_100\"            \n",
    "            df = pd.read_csv(f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}.csv')\n",
    "    else:\n",
    "        try:\n",
    "            indice = \"DOW_30\"\n",
    "            df = pd.read_csv(f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_nobasics.csv')\n",
    "        except:\n",
    "            indice = \"NASDAQ_100\"\n",
    "            df = pd.read_csv(f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_nobasics.csv')\n",
    "        \n",
    "    company_name, company_prompt = get_company_prompt(symbol)\n",
    "    insider_sentiment = get_insider_sentiment(symbol)\n",
    "    #prompt = insider_sentiment\n",
    "\n",
    "    prev_rows = []\n",
    "    all_prompts = []\n",
    "\n",
    "# calcluate 30 day moving average\n",
    "    closing_prices = []\n",
    "    for row_idx, row in df.iterrows():\n",
    "        closing_prices.append(row['End Price'])\n",
    "        \n",
    "    \n",
    "    ma_30 = calculate_30_day_ma(closing_prices)\n",
    "\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "\n",
    "        prompt = \"\"\n",
    "        if len(prev_rows) >= min_past_weeks:\n",
    "#            idx = min(random.choice(range(min_past_weeks, max_past_weeks+1)), len(prev_rows)) # Picking random news???? FIND ME\n",
    "            idx = min(max_past_weeks+1,len(prev_rows)) # pick minimum\n",
    "            for i in range(-idx, 0):  # FIND ME - not sure why this is being done\n",
    "                # Add Price Movement (Head)\n",
    "                prompt += \"\\n\" + prev_rows[i][0]\n",
    "\n",
    "                # Add News of previous weeks\n",
    "                sampled_news = sample_news(\n",
    "                    prev_rows[i][1],\n",
    "                    min(5, len(prev_rows[i][1])) # Picking  up to 5 stories?\n",
    "                )\n",
    "                if sampled_news:\n",
    "                    prompt += \"\\n\".join(sampled_news)\n",
    "                else:\n",
    "                    prompt += \"No relative news reported.\"\n",
    "\n",
    "        head, news, basics = get_prompt_by_row(symbol, company_name, row)\n",
    "        \n",
    "        prev_rows.append((head,news, basics, insider_sentiment))\n",
    "        if len(prev_rows) > max_past_weeks:\n",
    "            prev_rows.pop(0)  \n",
    "\n",
    "        if not prompt:\n",
    "            continue\n",
    "\n",
    "        prediction = map_bin_label(row['Bin Label'])\n",
    "        \n",
    "        prompt = company_prompt + '\\n' + insider_sentiment + '\\n' + prompt + '\\n' + basics\n",
    "        #prompt += f\"\\n\\nBased on all the information before {row['Start Date']}, let's first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "        #    f\"Then let's assume your prediction for next week ({row['Start Date']} to {row['End Date']}) is {prediction}. Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\"\n",
    "\n",
    "        prompt += f\"\\n\\nBased on all the information before {row['Start Date']} first, analyze the positive developments and potential concerns for {symbol}. Consider basic financials\" \\\n",
    "            f\" provided news events, 30 day moving average {ma_30}, and insider sentiments in your analysis. Then let's assume your prediction for next week ({row['Start Date']} to {row['End Date']}) is {prediction}. Provide summary analysis, with figures to support your prediction. The prediction result needs to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\"\n",
    "\n",
    "\n",
    "        all_prompts.append(prompt.strip())\n",
    "    \n",
    "    return all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92208b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. Your answer format should be as follows:\n",
      "\n",
      "[Positive Developments]:\n",
      "1. ...\n",
      "\n",
      "[Potential Concerns]:\n",
      "1. ...\n",
      "\n",
      "[Prediction & Analysis]:\n",
      "...\n",
      "\n",
      "[Company Introduction]:\n",
      "\n",
      "Apple Inc is a leading entity in the Technology sector. Incorporated and publicly traded since 1980-12-12, the company has established its reputation as one of the key players in the market. As of today, Apple Inc has a market capitalization of 2975178.09 in USD, with 15461.90 shares outstanding.\n",
      "\n",
      "Apple Inc operates primarily in the US, trading under the ticker AAPL on the NASDAQ NMS - GLOBAL MARKET. As a dominant force in the Technology space, the company continues to innovate and drive progress within the industry.\n",
      "[Insider Sentiment For]:AAPL \n",
      "\n",
      " The insider sentiment information is shown below. The MSPR ranges from -100 for the most negative to 100 for the most positive which can signal price changes in the coming 30-90 days.\n",
      "Year: 2022      Month:  2      Change:  -28436       MSPR:  -49.702858\n",
      "Year: 2022      Month:  3      Change:  13480       MSPR:  100\n",
      "Year: 2022      Month:  4      Change:  -458595       MSPR:  -26.980762\n",
      "Year: 2022      Month:  5      Change:  -26276       MSPR:  -100\n",
      "Year: 2022      Month:  8      Change:  -250366       MSPR:  -79.69429\n",
      "Year: 2022      Month:  9      Change:  814342       MSPR:  100\n",
      "Year: 2022      Month:  10      Change:  -1297681       MSPR:  -30.30565\n",
      "Year: 2022      Month:  11      Change:  -20200       MSPR:  -100\n",
      "Year: 2022      Month:  12      Change:  -2978       MSPR:  -100\n",
      "Year: 2023      Month:  2      Change:  -1685       MSPR:  -5.882353\n",
      "Year: 2023      Month:  3      Change:  -172914       MSPR:  -85.37024\n",
      "Year: 2023      Month:  4      Change:  -657849       MSPR:  -33.200634\n",
      "Year: 2023      Month:  5      Change:  -75634       MSPR:  -100\n",
      "Year: 2023      Month:  8      Change:  -37496       MSPR:  -37.01919\n",
      "Year: 2023      Month:  10      Change:  -286853       MSPR:  -7.2263374\n",
      "Year: 2023      Month:  11      Change:  -133767       MSPR:  -35.14053\n",
      "\n",
      "From 2023-01-08 to 2023-01-15, AAPL's stock price increased from 128.90 to 134.01. Company news during this period are listed below:\n",
      "\n",
      "No relative news reported.\n",
      "\n",
      "\n",
      " Some recent basic financials of AAPL, reported on 2022-12-31, are presented below:\n",
      "\n",
      "[Basic Financials]:\n",
      "\n",
      "assetTurnoverTTM: 1.1181\n",
      "bookValue: 56727\n",
      "cashRatio: 0.1495782526987457\n",
      "currentRatio: 0.938\n",
      "ebitPerShare: 2.2572\n",
      "eps: 1.88\n",
      "ev: 2157515\n",
      "fcfMargin: 0.2579\n",
      "fcfPerShareTTM: 6.1544\n",
      "grossMargin: 0.4296\n",
      "inventoryTurnoverTTM: 34.7615\n",
      "longtermDebtTotalAsset: 0.2873\n",
      "longtermDebtTotalCapital: 0.5936\n",
      "longtermDebtTotalEquity: 1.7563\n",
      "netDebtToTotalCapital: 0.5397\n",
      "netDebtToTotalEquity: 1.5967\n",
      "netMargin: 0.2561\n",
      "operatingMargin: 0.3074\n",
      "payoutRatioTTM: 0.1563\n",
      "pb: 36.4366\n",
      "peTTM: 21.7182\n",
      "pfcfTTM: 21.1998\n",
      "pretaxMargin: 0.3041\n",
      "psTTM: 5.3335\n",
      "quickRatio: 0.8883\n",
      "receivablesTurnoverTTM: 14.3625\n",
      "roaTTM: 0.2746\n",
      "roeTTM: 1.6345\n",
      "roicTTM: 0.5409\n",
      "rotcTTM: 0.6478\n",
      "salesPerShare: 7.3423\n",
      "sgaToSale: 0.5704\n",
      "totalDebtToEquity: 1.9587\n",
      "totalDebtToTotalAsset: 0.3204\n",
      "totalDebtToTotalCapital: 0.662\n",
      "totalRatio: 1.1956\n",
      "\n",
      "Based on all the information before 2023-01-15 first, analyze the positive developments and potential concerns for AAPL. Consider basic financials provided news events, 30 day moving average [167.4994893391927, 168.95099385579428, 170.1895528157552, 171.29809163411457, 172.4837422688802, 173.401931254069, 174.16346588134766, 175.11155649820964, 175.79705352783202, 176.77560170491537, 177.58363189697266, 178.0186309814453, 178.14412790934244, 178.55822143554687, 179.28680318196615, 180.13135935465496, 180.8305435180664, 181.4429178873698, 182.2295664469401, 182.992111714681, 183.61334838867188, 184.01540781656902, 184.03880106608074, 184.0885462443034, 183.9717809041341], and insider sentiments in your analysis. Then let's assume your prediction for next week (2023-01-15 to 2023-01-22) is up by 2-3%. Provide summary analysis, with figures to support your prediction. The prediction result needs to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\n"
     ]
    }
   ],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. \" \\\n",
    "    \"Your answer format should be as follows:\\n\\n[Positive Developments]:\\n1. ...\\n\\n[Potential Concerns]:\\n1. ...\\n\\n[Prediction & Analysis]:\\n...\\n\"\n",
    "\n",
    "print(SYSTEM_PROMPT)\n",
    "\n",
    "prompts = get_all_prompts(\"AAPL\", 1, 5)\n",
    "# prompts = get_all_prompts(\"MSFT\", 1, 3, False)\n",
    "#prompts = get_all_prompts(\"TRV\", 1, 4)\n",
    "\n",
    "print(prompts[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b010a45",
   "metadata": {},
   "source": [
    "# Request to GPT-3.5 OR 4 for Financial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e355117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(filename, input_data, output_data):\n",
    "    \n",
    "    with open(filename, mode='a', newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([input_data, output_data])\n",
    "\n",
    "        \n",
    "def initialize_csv(filename):\n",
    "    \n",
    "    with open(filename, mode='w', newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"prompt\", \"answer\"])\n",
    "\n",
    "def query_gpt_35(indice, symbol_list, min_past_weeks=1, max_past_weeks=3, with_basics=True):\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "        \n",
    "        csv_file = f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_gpt_35.csv' if with_basics else \\\n",
    "                   f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_nobasics_gpt_35.csv'\n",
    "        \n",
    "        if not os.path.exists(csv_file):\n",
    "            initialize_csv(csv_file)\n",
    "            pre_done = 0\n",
    "        else:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            pre_done = len(df)\n",
    "\n",
    "        prompts = get_all_prompts(symbol, min_past_weeks, max_past_weeks, with_basics)\n",
    "\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            \n",
    "            if i < pre_done:\n",
    "                continue\n",
    "\n",
    "            print(f\"{symbol} - {i}\")\n",
    "            \n",
    "            cnt = 0\n",
    "            while cnt < 5:\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                   )\n",
    "                    break    \n",
    "                except Exception:\n",
    "                    cnt += 1\n",
    "                    print(f'retry cnt {cnt}')\n",
    "            \n",
    "            answer = completion.choices[0].message.content if cnt < 5 else \"\"\n",
    "            append_to_csv(csv_file, prompt, answer)\n",
    "      \n",
    "\n",
    "def query_gpt4(indice,symbol_list, min_past_weeks=1, max_past_weeks=3, with_basics=True):\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "        \n",
    "        csv_file = f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_gpt-4.csv' if with_basics else \\\n",
    "                   f'{DATA_DIR}/{indice}_{symbol}_{START_DATE}_{END_DATE}_nobasics_gpt-4.csv'\n",
    "        \n",
    "        if not os.path.exists(csv_file):\n",
    "            initialize_csv(csv_file)\n",
    "            pre_done = 0\n",
    "        else:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            pre_done = len(df)\n",
    "\n",
    "        prompts = get_all_prompts(symbol, min_past_weeks, max_past_weeks, with_basics)\n",
    "\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            \n",
    "            if i < pre_done:\n",
    "                continue\n",
    "\n",
    "            print(f\"{symbol} - {i}\")\n",
    "            \n",
    "            cnt = 0\n",
    "            while cnt < 5:\n",
    "                try:\n",
    "                    completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                            {\"role\": \"user\", \"content\": prompt}\n",
    "                          ]\n",
    "                    )\n",
    "                    break    \n",
    "                except Exception:\n",
    "                    cnt += 1\n",
    "                    print(f'retry cnt {cnt}')\n",
    "            \n",
    "            answer = completion.choices[0].message.content if cnt < 5 else \"\"\n",
    "            append_to_csv(csv_file, prompt, answer)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ff6ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL - 0\n",
      "AAPL - 1\n",
      "AAPL - 2\n",
      "AAPL - 3\n",
      "AAPL - 4\n",
      "AAPL - 5\n",
      "AAPL - 6\n",
      "AAPL - 7\n",
      "AAPL - 8\n",
      "AAPL - 9\n",
      "AAPL - 10\n",
      "AAPL - 11\n",
      "AAPL - 12\n",
      "AAPL - 13\n",
      "AAPL - 14\n",
      "AAPL - 15\n",
      "AAPL - 16\n",
      "AAPL - 17\n",
      "AAPL - 18\n",
      "AAPL - 19\n",
      "AAPL - 20\n",
      "AAPL - 21\n",
      "AAPL - 22\n",
      "AAPL - 23\n",
      "AAPL - 24\n",
      "AAPL - 25\n",
      "AAPL - 26\n",
      "AAPL - 27\n",
      "AAPL - 28\n",
      "AAPL - 29\n",
      "AAPL - 30\n",
      "AAPL - 31\n",
      "AAPL - 32\n",
      "AAPL - 33\n",
      "AAPL - 34\n",
      "AAPL - 35\n",
      "AAPL - 36\n",
      "AAPL - 37\n",
      "AAPL - 38\n",
      "AAPL - 39\n",
      "AAPL - 40\n",
      "AAPL - 41\n",
      "AAPL - 42\n",
      "AAPL - 43\n",
      "AAPL - 44\n",
      "AAPL - 45\n",
      "AAPL - 46\n",
      "AAPL - 47\n",
      "AAPL - 48\n",
      "AAPL - 49\n",
      "AAPL - 50\n",
      "AAPL - 51\n",
      "AAPL - 52\n"
     ]
    }
   ],
   "source": [
    "# query_gpt4(DOW_30, 1, 3)\n",
    "#query_gpt4(DOW_30, 1, 4)\n",
    "#query_gpt4(['TRV'], 1, 4)\n",
    "#query_gpt_35(['TRV'],1,4)\n",
    "#query_gpt_35( 'DOW_30',['AAPL'],1,3)\n",
    "\n",
    "\n",
    "#for symbol in NASDAQ_100:\n",
    "#    query_gpt_35('NASDAQ_100',symbol,1,3)\n",
    "\n",
    "for symbol in DOW_30:\n",
    "    prepare_data_for_company( 'DOW_30',symbol,1,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ba9f0",
   "metadata": {},
   "source": [
    "# Transform into Llama2 Training Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2627f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4_to_llama(symbol, with_basics=True):\n",
    "    \n",
    "    csv_file = f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_gpt-4.csv' if with_basics else \\\n",
    "                   f'{DATA_DIR}/{symbol}_{START_DATE}_{END_DATE}_nobasics_gpt-4.csv'\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    prompts, answers, periods, labels = [], [], [], []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        prompt, answer = row['prompt'], row['answer']\n",
    "        \n",
    "        res = re.search(r\"Then let's assume your prediction for next week \\((.*)\\) is ((:?up|down) by .*%).\", prompt)\n",
    "        \n",
    "        period, label = res.group(1), res.group(2)\n",
    "#         label = label.replace('more than 5', '5+')\n",
    "        \n",
    "        prompt = re.sub(\n",
    "            r\"Then let's assume your prediction for next week \\((.*)\\) is (up|down) by ((:?.*)%). Provide a summary analysis to support your prediction. The prediction result need to be inferred from your analysis at the end, and thus not appearing as a foundational factor of your analysis.\", \n",
    "            f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\",\n",
    "            prompt\n",
    "        )\n",
    "        try:\n",
    "            answer = re.sub(\n",
    "                r\"\\[Prediction & Analysis\\]:\\s*\",\n",
    "                f\"[Prediction & Analysis]:\\nPrediction: {label.capitalize()}\\nAnalysis: \",\n",
    "                answer\n",
    "            )\n",
    "        except Exception:\n",
    "            print(symbol, i)\n",
    "            print(label)\n",
    "            print(answer)\n",
    "            continue\n",
    "            \n",
    "        new_system_prompt = SYSTEM_PROMPT.replace(':\\n...', '\\nPrediction: ...\\nAnalysis: ...')\n",
    "#         new_system_prompt = SYSTEM_PROMPT.replace(':\\n...', '\\nPrediction: {Up|Down} by {1-2|2-3|3-4|4-5|5+}%\\nAnalysis: ...')\n",
    "        \n",
    "        prompt = B_INST + B_SYS + new_system_prompt + E_SYS + prompt + E_INST\n",
    "        \n",
    "        prompts.append(prompt)\n",
    "        answers.append(answer)\n",
    "        periods.append(period)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return {\n",
    "        \"prompt\": prompts,\n",
    "        \"answer\": answers,\n",
    "        \"period\": periods,\n",
    "        \"label\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dataset(symbol_list, train_ratio=0.8, with_basics=True):\n",
    "\n",
    "    train_dataset_list = []\n",
    "    test_dataset_list = []\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "\n",
    "        data_dict = gpt4_to_llama(symbol, with_basics)\n",
    "#         print(data_dict['prompt'][-1])\n",
    "#         print(data_dict['answer'][-1])\n",
    "        symbols = [symbol] * len(data_dict['label'])\n",
    "        data_dict.update({\"symbol\": symbols})\n",
    "\n",
    "        dataset = Dataset.from_dict(data_dict)\n",
    "        train_size = round(train_ratio * len(dataset))\n",
    "\n",
    "        train_dataset_list.append(dataset.select(range(train_size)))\n",
    "        test_dataset_list.append(dataset.select(range(train_size, len(dataset))))\n",
    "\n",
    "    train_dataset = datasets.concatenate_datasets(train_dataset_list)\n",
    "    test_dataset = datasets.concatenate_datasets(test_dataset_list)\n",
    "\n",
    "    dataset = datasets.DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'test': test_dataset\n",
    "    })\n",
    "    \n",
    "    return dataset\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089b1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# v1\n",
    "# dow30_dataset = create_dataset(DOW30, True)\n",
    "# v2\n",
    "# dow30_nobasic_dataset = create_dataset(DOW_30, 0.8, False)\n",
    "# v3\n",
    "dow30_v3_dataset = create_dataset(DOW_30, 0.9)\n",
    "nasdaq100_v3_dataset = create_dataset(NASDAQ_100, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dow30_dataset.save_to_disk('fingpt-forecaster-dow30-20230601-20230930-llama')\n",
    "# dow30_nobasics_dataset.save_to_disk('fingpt-forecaster-dow30nobasics-20230601-20230930-llama')\n",
    "dow30_v3_dataset.save_to_disk('fingpt-forecaster-dow30v3-20221231-20230531-llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dow30_v3_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e711f",
   "metadata": {},
   "source": [
    "# Test-time Information Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "def get_curday():\n",
    "    \n",
    "    return date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def n_weeks_before(date_string, n):\n",
    "    \n",
    "    date = datetime.strptime(date_string, \"%Y-%m-%d\") - timedelta(days=7*n)\n",
    "    \n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def get_stock_data(stock_symbol, steps):\n",
    "\n",
    "    stock_data = yf.download(stock_symbol, steps[0], steps[-1])\n",
    "    \n",
    "#     print(stock_data)\n",
    "    \n",
    "    dates, prices = [], []\n",
    "    available_dates = stock_data.index.format()\n",
    "    \n",
    "    for date in steps[:-1]:\n",
    "        for i in range(len(stock_data)):\n",
    "            if available_dates[i] >= date:\n",
    "                prices.append(stock_data['Close'][i])\n",
    "                dates.append(datetime.strptime(available_dates[i], \"%Y-%m-%d\"))\n",
    "                break\n",
    "\n",
    "    dates.append(datetime.strptime(available_dates[-1], \"%Y-%m-%d\"))\n",
    "    prices.append(stock_data['Close'][-1])\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"Start Date\": dates[:-1], \"End Date\": dates[1:],\n",
    "        \"Start Price\": prices[:-1], \"End Price\": prices[1:]\n",
    "    })\n",
    "\n",
    "\n",
    "def get_current_basics(symbol, curday):\n",
    "\n",
    "    basic_financials = finnhub_client.company_basic_financials(symbol, 'all')\n",
    "    \n",
    "    final_basics, basic_list, basic_dict = [], [], defaultdict(dict)\n",
    "    \n",
    "    for metric, value_list in basic_financials['series']['quarterly'].items():\n",
    "        for value in value_list:\n",
    "            basic_dict[value['period']].update({metric: value['v']})\n",
    "\n",
    "    for k, v in basic_dict.items():\n",
    "        v.update({'period': k})\n",
    "        basic_list.append(v)\n",
    "        \n",
    "    basic_list.sort(key=lambda x: x['period'])\n",
    "    \n",
    "    for basic in basic_list[::-1]:\n",
    "        if basic['period'] <= curday:\n",
    "            break\n",
    "            \n",
    "    return basic\n",
    "    \n",
    "\n",
    "def get_all_prompts_online(symbol, data, curday, with_basics=True):\n",
    "\n",
    "    company_name, company_prompt = get_company_prompt(symbol)\n",
    " \n",
    "    prev_rows = []\n",
    "\n",
    "    for row_idx, row in data.iterrows():\n",
    "        head, news, _ , _= get_prompt_by_row(symbol, row)\n",
    "        prev_rows.append((head, news, None))\n",
    "        \n",
    "    prompt = \"\"\n",
    "    for i in range(-len(prev_rows), 0):\n",
    "        prompt += \"\\n\" + prev_rows[i][0]\n",
    "        sampled_news = sample_news(\n",
    "            prev_rows[i][1],\n",
    "            min(5, len(prev_rows[i][1]))\n",
    "        )\n",
    "        if sampled_news:\n",
    "            prompt += \"\\n\".join(sampled_news)\n",
    "        else:\n",
    "            prompt += \"No relative news reported.\"\n",
    "        \n",
    "    period = \"{} to {}\".format(curday, n_weeks_before(curday, -1))\n",
    "    \n",
    "    if with_basics:\n",
    "        basics = get_current_basics(symbol, curday)\n",
    "        basics = \"\\n\\n Some recent basic financials of {}, reported on {}, are presented below:\\n\\n[Basic Financials]:\\n\\n\".format(\n",
    "            symbol, basics['period']) + \"\\n\".join(f\"{k}: {v}\" for k, v in basics.items() if k != 'period')\n",
    "    else:\n",
    "        basics = \"[Basic Financials]:\\n\\nNo basic financial reported.\"\n",
    "\n",
    "    info = company_prompt + '\\n' + prompt + '\\n' + basics\n",
    "    prompt = info + f\"\\n\\nBased on all the information before {curday}, first analyze the positive developments and potential concerns for {symbol}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. \" \\\n",
    "        f\"Then make your prediction of the {symbol} stock price movement for next week ({period}). Provide a summary analysis to support your prediction.\"\n",
    "        \n",
    "    return info, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48aab1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "n_weeks = 2\n",
    "curday = get_curday()\n",
    "steps = [n_weeks_before(curday, n) for n in range(n_weeks + 1)][::-1]\n",
    "\n",
    "data = get_stock_data(ticker, steps)\n",
    "\n",
    "data = get_news(ticker, data)\n",
    "\n",
    "data['Basics'] = [json.dumps({})] * len(data)\n",
    "# data = get_basics(ticker, data, always=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "info, prompt = get_all_prompts_online(ticker, data, curday, False)\n",
    "\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
